{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# EE 467 Lab 2: Breaking CAPTCHAs with PyTorch\n"
      ],
      "metadata": {
        "id": "tkeyDlLI3BHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Breaking CAPTCHAs with PyTorch\n",
        "# ========================================\n",
        "\n",
        "# 0️⃣ Install required libraries\n",
        "# Use CPU or GPU version of PyTorch\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "!pip install matplotlib scikit-learn \"opencv-python>4\" imutils\n",
        "\n",
        "# 0️⃣.1 Extract CAPTCHA images\n",
        "!tar -xf captcha-images.tar.xz\n",
        "\n",
        "# ========================================\n",
        "# 1️⃣ Imports\n",
        "# ========================================\n",
        "import os, pickle\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from imutils import paths\n",
        "from lab_2_helpers import *\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCnh8HNd5Ebb",
        "outputId": "353d6e51-d524-42ce-c090-e341a67ed6ec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (80.10.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2026.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: opencv-python>4 in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.12/dist-packages (0.5.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ========================================\n",
        "# 2️⃣ Load CAPTCHA images\n",
        "# ========================================\n",
        "CAPTCHA_IMAGE_FOLDER = \"./captcha-images\"\n",
        "\n",
        "captcha_image_paths = list(paths.list_images(CAPTCHA_IMAGE_FOLDER))\n",
        "\n",
        "def extract_captcha_text(path):\n",
        "    return os.path.splitext(os.path.basename(path))[0]\n",
        "\n",
        "captcha_texts = [extract_captcha_text(p) for p in captcha_image_paths]\n",
        "\n",
        "def load_transform_image(path):\n",
        "    img = cv2.imread(path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    padded = cv2.copyMakeBorder(gray, 8, 8, 8, 8, cv2.BORDER_REPLICATE)\n",
        "    return padded\n",
        "\n",
        "captcha_images = [load_transform_image(p) for p in captcha_image_paths]"
      ],
      "metadata": {
        "id": "20x9coBw5X1s"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# 3️⃣ Train / Test split\n",
        "# ========================================\n",
        "TVT_SPLIT_SEED = 31528476\n",
        "\n",
        "imgs_tv, imgs_test, texts_tv, texts_test = train_test_split(\n",
        "    captcha_images, captcha_texts, test_size=0.2, random_state=TVT_SPLIT_SEED\n",
        ")"
      ],
      "metadata": {
        "id": "hNWaYlr25eAB"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ========================================\n",
        "# 4️⃣ Character extraction\n",
        "# ========================================\n",
        "def extract_chars(image):\n",
        "    bw = cv2.threshold(image, 0, 255,\n",
        "                       cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "    contours = cv2.findContours(\n",
        "        bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
        "    )[0]\n",
        "\n",
        "    regions = []\n",
        "    for c in contours:\n",
        "        x, y, w, h = cv2.boundingRect(c)\n",
        "        if w / h > 1.25:\n",
        "            hw = w // 2\n",
        "            regions += [(x, y, hw, h), (x+hw, y, hw, h)]\n",
        "        else:\n",
        "            regions.append((x, y, w, h))\n",
        "\n",
        "    if len(regions) != 4:\n",
        "        return None\n",
        "\n",
        "    regions.sort(key=lambda r: r[0])\n",
        "    chars = [\n",
        "        image[y-2:y+h+2, x-2:x+w+2]\n",
        "        for x, y, w, h in regions\n",
        "    ]\n",
        "    return chars\n",
        "\n",
        "CHAR_IMAGE_FOLDER = f\"./char-images-{TVT_SPLIT_SEED}\"\n",
        "os.makedirs(CHAR_IMAGE_FOLDER, exist_ok=True)\n",
        "char_counts = {}\n",
        "\n",
        "def save_chars(chars, text):\n",
        "    for img, ch in zip(chars, text):\n",
        "        folder = os.path.join(CHAR_IMAGE_FOLDER, ch)\n",
        "        os.makedirs(folder, exist_ok=True)\n",
        "        count = char_counts.get(ch, 1)\n",
        "        cv2.imwrite(os.path.join(folder, f\"{count}.png\"), img)\n",
        "        char_counts[ch] = count + 1\n",
        "\n",
        "for img, text in zip(imgs_tv, texts_tv):\n",
        "    chars = extract_chars(img)\n",
        "    if chars:\n",
        "        save_chars(chars, text)"
      ],
      "metadata": {
        "id": "PbYqQMmH5iyY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# 5️⃣ Feature and label encoding\n",
        "# ========================================\n",
        "def make_feature(img):\n",
        "    img = resize_to_fit(img, 20, 20)\n",
        "    return img[..., None]\n",
        "\n",
        "X, y = [], []\n",
        "for path in paths.list_images(CHAR_IMAGE_FOLDER):\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) # Corrected flag here\n",
        "    X.append(make_feature(img))\n",
        "    y.append(os.path.basename(os.path.dirname(path)))\n",
        "\n",
        "X = np.array(X, dtype=\"float32\") / 255.0\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "y_onehot = lb.fit_transform(y)\n",
        "n_classes = len(lb.classes_)\n",
        "\n",
        "with open(\"labels.pkl\", \"wb\") as f:\n",
        "    pickle.dump(lb, f)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, np.argmax(y_onehot, axis=1), test_size=0.25, random_state=955996\n",
        ")"
      ],
      "metadata": {
        "id": "s3uFLLgt5nsn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# 6️⃣ PyTorch Dataset\n",
        "# ========================================\n",
        "class CharDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X).permute(0, 3, 1, 2)\n",
        "        self.y = torch.tensor(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.X[i], self.y[i]\n",
        "\n",
        "train_loader = DataLoader(CharDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(CharDataset(X_val, y_val), batch_size=32)"
      ],
      "metadata": {
        "id": "wkB16dTj5rXq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ========================================\n",
        "# 7️⃣ CNN Model\n",
        "# ========================================\n",
        "class CaptchaCNN(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 20, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(20, 50, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(50*5*5, 500),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(500, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "model = CaptchaCNN(n_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "GErOyabf5vKM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ========================================\n",
        "# 8️⃣ Training\n",
        "# ========================================\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(x), y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            preds = model(x).argmax(1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Val Acc: {correct/total:.4f}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"captcha-model-pytorch.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV4B8_xh52-K",
        "outputId": "bd056c5b-71c6-44fb-ed4b-21d7278760c0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Val Acc: 0.8709\n",
            "Epoch 2/10 | Val Acc: 0.9461\n",
            "Epoch 3/10 | Val Acc: 0.9719\n",
            "Epoch 4/10 | Val Acc: 0.9809\n",
            "Epoch 5/10 | Val Acc: 0.9877\n",
            "Epoch 6/10 | Val Acc: 0.9854\n",
            "Epoch 7/10 | Val Acc: 0.9843\n",
            "Epoch 8/10 | Val Acc: 0.9854\n",
            "Epoch 9/10 | Val Acc: 0.9854\n",
            "Epoch 10/10 | Val Acc: 0.9854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ========================================\n",
        "# 9️⃣ End-to-end evaluation on CAPTCHA images\n",
        "# ========================================\n",
        "model.eval()\n",
        "features_test = []\n",
        "failed = []\n",
        "\n",
        "for i, img in enumerate(imgs_test):\n",
        "    chars = extract_chars(img)\n",
        "    if chars:\n",
        "        features_test.extend([make_feature(c) for c in chars])\n",
        "    else:\n",
        "        failed.append(i)\n",
        "        features_test.extend(np.zeros((4,20,20,1)))\n",
        "\n",
        "X_test = torch.tensor(features_test, dtype=torch.float32).permute(0,3,1,2).to(device)\n",
        "with torch.no_grad():\n",
        "    preds = model(X_test).argmax(1).cpu().numpy()\n",
        "\n",
        "pred_chars = lb.classes_[preds]\n",
        "pred_texts = [\"\".join(c) for c in group_every(pred_chars, 4)]\n",
        "\n",
        "for i in failed:\n",
        "    pred_texts[i] = \"-\"\n",
        "\n",
        "accuracy = sum(p==t for p,t in zip(pred_texts, texts_test)) / len(texts_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h85a1XrW57vX",
        "outputId": "cce06404-389a-489c-cc1a-76a9c30b06aa"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9605263157894737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38b6417e",
        "outputId": "f8e4a5be-3e7b-42d9-ad0a-e235d4dd83dd"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"labels.pkl\", \"rb\") as f:\n",
        "    lb_loaded = pickle.load(f)\n",
        "\n",
        "print(\"LabelBinarizer classes:\", lb_loaded.classes_)\n",
        "\n",
        "# Also inspect a few predicted vs actual texts to see the mismatch clearly\n",
        "print(\"\\nSample predicted texts vs actual texts:\")\n",
        "for i in range(min(5, len(pred_texts))):\n",
        "    print(f\"Predicted: {pred_texts[i]}, Actual: {texts_test[i]}\")\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LabelBinarizer classes: ['2' '3' '4' '5' '6' '7' '8' '9' 'A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'J' 'K'\n",
            " 'L' 'M' 'N' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z']\n",
            "\n",
            "Sample predicted texts vs actual texts:\n",
            "Predicted: 2QSL, Actual: 2QSL\n",
            "Predicted: 2SKC, Actual: 2SKC\n",
            "Predicted: 8AWH, Actual: 8AWH\n",
            "Predicted: 4GUC, Actual: 4GUC\n",
            "Predicted: B5PF, Actual: B5PF\n"
          ]
        }
      ]
    }
  ]
}